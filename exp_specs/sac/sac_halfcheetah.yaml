meta_data:
  script_path: run_scripts/sac_alpha_exp_script.py
  exp_name: test_sac_halfcheetah
  description: Train an agent using Soft-Actor-Critic
  num_workers: 2
  using_gpus: true
  # num_gpu_workers: 1
# -----------------------------------------------------------------------------
variables:
  seed: [0]

# -----------------------------------------------------------------------------
constants:
  net_size: 256
  num_hidden_layers: 2

  rl_alg_params:
    num_epochs: 202
    num_steps_per_epoch: 10000
    num_steps_between_train_calls: 1000
    num_train_steps_per_train_call: 1000
    max_path_length: 1000
    min_steps_before_training: 5000

    eval_deterministic: true
    num_steps_per_eval: 20000

    batch_size: 256
    replay_buffer_size: 1000000
    no_terminal: false
    wrap_absorbing: false

    save_best: false
    freq_saving: 10
    save_replay_buffer: false
    # save_environment: false
    # save_environment: false

  sac_params:
    reward_scale: 1.0
    discount: 0.99
    soft_target_tau: 0.005
    beta_1: 0.25
    policy_lr: 0.0003
    qf_lr: 0.0003
    vf_lr: 0.0003
    policy_mean_reg_weight: 0.001
    policy_std_reg_weight: 0.001

  env_specs:
    env_name: 'halfcheetah'
    env_kwargs: {}
    env_num: 1
    # vec_env_kwargs:
    #   norm_obs: true