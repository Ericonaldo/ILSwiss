meta_data:
  script_path: run_scripts/sac_alpha_visual_exp_script.py
  exp_name: test_sac_rad_dmc_finger_turn_easy
  description: Train an agent using Soft-Actor-Critic
  num_workers: 2
  using_gpus: true
  # num_gpu_workers: 1
# -----------------------------------------------------------------------------
variables:
  seed: [0,1,2]

# -----------------------------------------------------------------------------
constants:
  net_size: 1024
  num_hidden_layers: 2

  rl_alg_params:
    num_epochs: 2020
    num_steps_per_epoch: 1000
    num_steps_between_train_calls: 1
    num_train_steps_per_train_call: 1
    num_steps_per_eval: 5000
    max_path_length: 1000
    min_steps_before_training: 1000

    eval_deterministic: true

    batch_size: 512
    replay_buffer_size: 100000
    no_terminal: false
    wrap_absorbing: false

    save_best: true
    freq_saving: 1
    save_replay_buffer: false

  encoder_params:
    encoder_feature_dim: 50
    encoder_type: 'pixel'
    decoder_type: 'pixel'
    num_layers: 4
    num_filters: 32

  augmentation_params:
    data_augs: 'translate'
    image_size: 108
    pre_transform_image_size: 100

  sac_params:
    alpha: 0.1
    reward_scale: 1.0
    discount: 0.99
    soft_target_tau: 0.01
    enc_soft_target_tau: 0.05
    policy_lr: 0.0002
    qf_lr: 0.0002
    encdec_lr: 0.0002
    alpha_lr: 0.0001
    policy_mean_reg_weight: 0.0002
    policy_std_reg_weight: 0.0002
    ac_update_freq: 2
    encdec_update_freq: 0 # So that we do not use reconstruction error to update encdec

  env_specs:
    env_name: 'dmc'
    frame_stack: 3
    env_kwargs: 
      domain_name: "finger"
      task_name: "turn_easy"
      visualize_reward: false
      from_pixels: true
      height: 100
      width: 100
      frame_skip: 4
    env_num: 1
